{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.distance import distance\n",
    "\n",
    "import math\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "from typing import List, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query GraphQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def query_graphql(start_time: int, end_time: int, route: str) -> list:\n",
    "    query = f\"\"\"{{\n",
    "        trynState(agency: \"muni\",\n",
    "                  startTime: \"{start_time}\",\n",
    "                  endTime: \"{end_time}\",\n",
    "                  routes: [\"{route}\"]) {{\n",
    "            agency\n",
    "            startTime\n",
    "            routes {{\n",
    "                stops {{\n",
    "                    sid\n",
    "                    lat\n",
    "                    lon\n",
    "                }}\n",
    "                routeStates {{\n",
    "                    vtime\n",
    "                    vehicles {{\n",
    "                        vid\n",
    "                        lat\n",
    "                        lon\n",
    "                        did\n",
    "                    }}\n",
    "                }}\n",
    "            }}\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    query_url = f\"https://06o8rkohub.execute-api.us-west-2.amazonaws.com/dev/graphql?query={query}\"\n",
    "\n",
    "    request = requests.get(query_url).json()\n",
    "    try:\n",
    "        return request['data']['trynState']['routes']\n",
    "    except KeyError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce Datatables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_stops(data: list, route: str) -> pd.DataFrame:\n",
    "    stops = pd.io.json.json_normalize(data,\n",
    "                                      record_path=['stops']) \\\n",
    "            .rename(columns={'lat': 'LAT',\n",
    "                             'lon': 'LON',\n",
    "                             'sid': 'SID'}) \\\n",
    "            .reindex(['SID', 'LAT', 'LON'], axis='columns')\n",
    "    \n",
    "    # obtain stop directions\n",
    "    stops['DID'] = stops['SID'].map({stop: direction['id']\n",
    "                                     for direction in requests\n",
    "                                                      .get(f\"http://restbus.info/api/agencies/sf-muni/routes/{route}\")\n",
    "                                                      .json()['directions']\n",
    "                                     for stop in direction['stops']})\n",
    "    \n",
    "    # remove stops that don't have an associated direction\n",
    "    stops = stops.dropna(axis='index', subset=['DID'])\n",
    "    \n",
    "    # obtain stop ordinals\n",
    "    stops['ORD'] = stops['SID'].map({stop_meta['id']: ordinal\n",
    "                                     for ordinal, stop_meta\n",
    "                                     in enumerate(requests\n",
    "                                                  .get(\"http://restbus.info/api/agencies/sf-muni/\"\n",
    "                                                       f\"routes/{route}\")\n",
    "                                                  .json()['stops'])})\n",
    "    \n",
    "    return stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def produce_buses(data: list) -> pd.DataFrame:\n",
    "     return pd.io.json.json_normalize(data,\n",
    "                                      record_path=['routeStates', 'vehicles'],\n",
    "                                      meta=[['routeStates', 'vtime']]) \\\n",
    "            .rename(columns={'lat': 'LAT',\n",
    "                             'lon': 'LON',\n",
    "                             'vid': 'VID',\n",
    "                             'did': 'DID',\n",
    "                             'routeStates.vtime': 'TIME'}) \\\n",
    "            .reindex(['TIME', 'VID', 'LAT', 'LON', 'DID'], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eclipses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def distance_func(dstop,dbus):\n",
    "    latmid = (dstop['LON']+ dbus['LAT'])/2\n",
    "    m_per_lat = 111132.954 - 559.822 * np.cos( 2 * latmid ) + 1.175 * np.cos( 4 * latmid);\n",
    "    m_per_lon = 111132.954 * np.cos(latmid );\n",
    "    \n",
    "    delta_lat = math.fabs(dbus['LAT'] - dstop['LAT'])\n",
    "    delta_lon = math.fabs(dbus['LON'] - dstop['LON'])\n",
    "    \n",
    "    distance = np.sqrt(pow(delta_lon * m_per_lat,2) + pow(delta_lon * m_per_lon ,2));\n",
    "    \n",
    "    \n",
    "    return distance\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def distance_func(dstop,dbus):\n",
    "    \n",
    "    eradius = 6378.137\n",
    "    \n",
    "    lat1 = dstop['LAT']\n",
    "    lat2 = dbus['LAT']\n",
    "    lon1 = dstop['LON']\n",
    "    lon2 = dbus['LON']\n",
    "    \n",
    "    distance = eradius * np.arccos(\n",
    "        np.sin(lat1) * np.sin(lat2)\n",
    "        + np.cos(lat1) * np.cos(lat2) * np.cos(lon2-lon1))\n",
    "    \n",
    "    #distance = 1\n",
    "    return distance\n",
    "\n",
    "def find_eclipses(buses, stop):\n",
    "    \"\"\"\n",
    "    Find movement of buses relative to the stop, in distance as a function of time.\n",
    "    \"\"\"\n",
    "    def split_eclipses(eclipses, threshold=30*60*1000) -> List[pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Split buses' movements when they return to a stop after completing the route.\n",
    "        \"\"\"\n",
    "        disjoint_eclipses = []\n",
    "        for bus_id in eclipses['VID'].unique():\n",
    "            # obtain distance data for this bus\n",
    "            bus = eclipses[eclipses['VID'] == bus_id].sort_values('TIME')\n",
    "\n",
    "            # split data into groups when there is at least a `threshold`-ms gap between data points\n",
    "            group_ids = (bus['TIME'] > (bus['TIME'].shift() + threshold)).cumsum()\n",
    "\n",
    "            # store groups\n",
    "            for _, group in bus.groupby(group_ids):\n",
    "                disjoint_eclipses.append(group)\n",
    "        return disjoint_eclipses\n",
    "\n",
    "    eclipses = buses.copy()\n",
    "    \n",
    "    #print('elicpses = buses.copy()')\n",
    "    #print(eclipses)\n",
    "    #print('stop:')\n",
    "    #print(stop)\n",
    "    #pprint.pprint(stop[['LAT', 'LON']])\n",
    "    #pprint.pprint(bus[['LAT', 'LON']])\n",
    "    \n",
    "    print('eclipses lmbda start')\n",
    "    starttime=time.time()\n",
    "    \n",
    "    stopcopy = stop[['LAT', 'LON']].values\n",
    "    buscopy = eclipses[['LAT', 'LON']].values\n",
    "    \n",
    "    #eclipses['DIST'] = eclipses.apply(lambda row: distance(stop[['LAT','LON']],row[['LAT','LON']]).meters,axis=1)\n",
    "    dfromstop = []   \n",
    "    for row,value in enumerate(buscopy):\n",
    "        busdistance = distance(stopcopy,value)\n",
    "        dfromstop.append(busdistance)\n",
    "    \n",
    "    eclipses['DIST'] = dfromstop\n",
    "    \n",
    "    # with defined great circle simplified method, 10.033411979675293 seconds\n",
    "    # with geopy distance, 10.88465404510498 seconds\n",
    "    # reduced timespan from 3 hour to 1 hour, as expected elapsed time 3.1001999378204346 seconds\n",
    "    \n",
    "    print('eclipses lmbda end')\n",
    "    print('elapsed time for eclipses lmbda is: %s seconds' % (time.time()-starttime))\n",
    "          \n",
    "    eclipses['TIME'] = eclipses['TIME'].astype(np.int64)\n",
    "    eclipses = eclipses[['TIME', 'VID', 'DIST']]\n",
    "    \n",
    "    # only keep positions within 750 meters\n",
    "    eclipses = eclipses[eclipses['DIST'] < 750]\n",
    "    \n",
    "    eclipses = split_eclipses(eclipses)\n",
    "    \n",
    "    return eclipses\n",
    "\n",
    "def find_nadirs(eclipses):\n",
    "    \"\"\"\n",
    "    Find points where buses are considered to have encountered the stop.\n",
    "    \n",
    "    Nadir is an astronomical term that describes the lowest point reached by an orbiting body.\n",
    "    \"\"\"\n",
    "    def calc_nadir(eclipse: pd.DataFrame) -> Union[pd.Series, None]:\n",
    "        nadir = eclipse.iloc[eclipse['DIST'].values.argmin()]\n",
    "        if nadir['DIST'] < 100:  # if min dist < 100, then reasonable candidate for nadir\n",
    "            return nadir\n",
    "        else:  # otherwise, hardcore datasci is needed\n",
    "            rev_eclipse = eclipse.iloc[::-1]\n",
    "            rev_nadir = rev_eclipse.iloc[rev_eclipse['DIST'].values.argmin()]\n",
    "            if nadir['TIME'] == rev_nadir['TIME']:  # if eclipse has a global min\n",
    "                return nadir  # then it's the best candidate for nadir\n",
    "            else:  # if eclipse's min occurs at two times\n",
    "                mid_nadir = nadir.copy()\n",
    "                mid_nadir['DIST'] = (nadir['DIST'] + rev_nadir['DIST'])/2\n",
    "                return mid_nadir  # take the midpoint of earliest and latest mins\n",
    "    \n",
    "    nadirs = []\n",
    "    for eclipse in eclipses:\n",
    "        nadirs.append(calc_nadir(eclipse)[['VID', 'TIME']])\n",
    "        \n",
    "    return pd.DataFrame(nadirs)\n",
    "            \n",
    "    \n",
    "def show_stop(eclipses, nadirs):\n",
    "    fig = plt.figure(figsize=(18, 9))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    for eclipse in eclipses:\n",
    "        plt.plot(*eclipse[['TIME', 'DIST']].values.T)\n",
    "        \n",
    "    for nadir_time in nadirs['TIME']:\n",
    "        plt.axvline(nadir_time, linestyle='--', linewidth=.5)\n",
    "\n",
    "    # format plot\n",
    "    ax.get_xaxis().set_major_formatter(  # convert x-axis tick labels to time of day\n",
    "        FuncFormatter(lambda x, p: datetime.fromtimestamp(int(x)//1000).strftime('%I:%M%p')))\n",
    "    plt.title(f\"Eclipses at Stop {stop_id}\"\n",
    "              f\" from {datetime.fromtimestamp(int(start_time)//1000).strftime('%a %b %d %I:%M%p')}\"\n",
    "              f\" to {datetime.fromtimestamp(int(end_time)//1000).strftime('%a %b %d %I:%M%p')}\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Distance from Stop (meters)\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardcore Data Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route = [\"12\", \"14\"]\n",
    "\n",
    "timespan = (\"08:00\",\n",
    "            \"11:00\")\n",
    "\n",
    "dates = [\n",
    "    \"2018-11-12\",\n",
    "    \"2018-11-13\",\n",
    "    \"2018-11-14\",\n",
    "    \"2018-11-15\",\n",
    "    \"2018-11-16\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue: The plot is labeled based on the machine's current timezone, which may not necessarily match the times sent to the API. To remedy this, the logic for displaying the plot would have to be adjusted to account for the UTC offset of the epochs we get back from the API, which I'm hoping there's a module for but I'm not presently familiar with any."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue: currently, if a trajectory looks like `/~V`, the left edge is selected as the nadir. Based on the data, I suspect that the initial upslope may be a GPS glitch as it's being initialized, I believe the trough on the right should be selected instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BusData:\n",
    "    def __init__(self):\n",
    "        self.data = {}\n",
    "    \n",
    "    @property\n",
    "    def routes(self):\n",
    "        return list(self.data.keys())\n",
    "    \n",
    "    @property\n",
    "    def stops(self, route_id):\n",
    "        return list(self.data.get(route_id, {}).keys())\n",
    "    \n",
    "    def append(self, other_data):\n",
    "        for route_id, other_route in other_data.items():\n",
    "            route = self.data.get(route_id)\n",
    "            if route:\n",
    "                for stop_id, other_stop in other_route.items():\n",
    "                    stop = route.get(stop_id)\n",
    "                    if stop:\n",
    "                        stop['eclipses'].extend(other_stop['eclipses'])\n",
    "                    else:\n",
    "                        route[stop_id] = other_stop\n",
    "            else:\n",
    "                self.data[route_id] = other_route\n",
    "    \n",
    "    @classmethod\n",
    "    def read_file(cls, filename):\n",
    "        bus_data = cls()\n",
    "        with open(filename, 'r') as f:\n",
    "            bus_data.append(json.load(f))\n",
    "        return bus_data\n",
    "                \n",
    "    \n",
    "    def write_file(self, filename):\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(self.data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BusData.data` specification:\n",
    "```\n",
    "{\n",
    "    route_id: {  # route_id is a str\n",
    "        stop_id: {  # stop_id is a str\n",
    "            direction_id: str,\n",
    "            order: int,\n",
    "            lat: float,\n",
    "            lon: float,\n",
    "            eclipses: [\n",
    "                {\n",
    "                    bus_id: int,\n",
    "                    timestamp: int,\n",
    "                },\n",
    "                {\n",
    "                    bus_id: int,\n",
    "                    timestamp: int,\n",
    "                },\n",
    "                ...\n",
    "            ]\n",
    "        },\n",
    "        ...\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# grab a couple of sequential stops to look at\n",
    "# get_stop_times(date, stop [time, route, dir])\n",
    "# returns a df w/columns: vID, date, time, stop, route, dir\n",
    "# ISSUE: really slow, any way to speed up graphQL query?\n",
    "\n",
    "# routes = pd.DataFrame(columns = [\"VID\", \"TIME\", \"SID\", \"DID\", \"ROUTE\"])\n",
    "\n",
    "# stop_ids = [stop['id']\n",
    "#             for stop\n",
    "#             in requests.get(f\"http://restbus.info/api/agencies/sf-muni/routes/{route}\").json()['stops']][2:4]\n",
    "\n",
    "# bus_data = BusData()\n",
    "\n",
    "# for stop_id in stop_ids:\n",
    "#     for date in dates:\n",
    "#         start_time = int(datetime.strptime(f\"{date} {timespan[0]} -0800\", \"%Y-%m-%d %H:%M %z\").timestamp())*1000\n",
    "#         end_time   = int(datetime.strptime(f\"{date} {timespan[1]} -0800\", \"%Y-%m-%d %H:%M %z\").timestamp())*1000\n",
    "\n",
    "#         data = query_graphql(start_time, end_time, route)\n",
    "\n",
    "#         if data is None:  # API might refuse to cooperate\n",
    "#             print(\"API probably timed out\")\n",
    "#             continue\n",
    "#         elif len(data) == 0:  # some days somehow have no data\n",
    "#             print(f\"no data for {month}/{day}\")\n",
    "#             continue\n",
    "#         else:\n",
    "#             stops = produce_stops(data)\n",
    "#             buses = produce_buses(data)\n",
    "\n",
    "#             stop = stops[stops['SID'] == stop_id].squeeze()\n",
    "#             buses = buses[buses['DID'] == stop['DID']]\n",
    "\n",
    "#             eclipses = find_eclipses(buses, stop)\n",
    "#             nadirs = find_nadirs(eclipses)\n",
    "#             nadirs[\"TIME\"] = nadirs[\"TIME\"].apply(lambda x: datetime.fromtimestamp(x//1000, timezone(timedelta(hours = -8))).strftime('%a %b %d %I:%M%p'))\n",
    "#             nadirs[\"SID\"] = stop_id\n",
    "#             nadirs[\"DID\"] = stop[\"DID\"]\n",
    "#             nadirs[\"ROUTE\"] = route\n",
    "#             routes = routes.append(nadirs)\n",
    "\n",
    "\n",
    "#             show_stop(eclipses, nadirs)\n",
    "\n",
    "#             bus_data.append({\n",
    "#                 route: {\n",
    "#                     stop_id: {\n",
    "#                         'direction_id': stop['DID'],\n",
    "#                         'order': int(stop['ORD']),\n",
    "#                         'lat': stop['LAT'],\n",
    "#                         'lon': stop['LON'],\n",
    "#                         'eclipses': [\n",
    "#                             {\n",
    "#                                 'bus_id': bus_id,\n",
    "#                                 'timestamp': int(timestamp)\n",
    "#                             }\n",
    "#                             for bus_id, timestamp in zip(nadirs['VID'].tolist(),\n",
    "#                                                          nadirs['TIME'].tolist())\n",
    "#                         ]\n",
    "#                     }\n",
    "#                 }\n",
    "#             })\n",
    "        \n",
    "# bus_data.write_file(\"bus_data.json\")\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_stops\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# parameters:\n",
    "# dates: an array of dates, formatted as strings in the form YYYY-MM-DD\n",
    "# routes: an array of routes, each represented as a string\n",
    "# directions: an array of strings representing the directions to filter\n",
    "# stops: an array of strings representing the stops to filter\n",
    "# times: a tuple with the start and end times (in UTC -8:00) as strings in the form HH:MM \n",
    "# \n",
    "# returns:\n",
    "# stops: a DataFrame, filtered by the given directions and stops, with the following columns:\n",
    "# VID: the vehicle ID\n",
    "# Time: a datetime object representing the date/time of the stop\n",
    "# Route: the route on which the stop occurred\n",
    "# Stop: the stop at which the stop occurred\n",
    "# Dir: the direction in which the stop occurred\n",
    "# -------------------------------------------------------------------------------------------\n",
    "def get_stops(dates, routes, directions = [], new_stops = [], times = (\"00:00\", \"23:59\")):\n",
    "    bus_stops = pd.DataFrame(columns = [\"VID\", \"TIME\", \"SID\", \"DID\", \"ROUTE\"])\n",
    "    \n",
    "    for route in routes:\n",
    "        stop_ids = [stop['id']\n",
    "            for stop\n",
    "            in requests.get(f\"http://restbus.info/api/agencies/sf-muni/routes/{route}\").json()['stops']][2:4]\n",
    "\n",
    "        for stop_id in stop_ids:\n",
    "            # check if stops to filter were provided, or if the stop_id is in the list of filtered stops\n",
    "            if (stop_id in new_stops) ^ (len(new_stops) == 0):\n",
    "                for date in dates:\n",
    "                    print(f\"{datetime.now().strftime('%a %b %d %I:%M:%S %p')}: starting processing on stop {stop_id} on route {route} on {date}.\")\n",
    "                    start_time = int(datetime.strptime(f\"{date} {timespan[0]} -0800\", \"%Y-%m-%d %H:%M %z\").timestamp())*1000\n",
    "                    end_time   = int(datetime.strptime(f\"{date} {timespan[1]} -0800\", \"%Y-%m-%d %H:%M %z\").timestamp())*1000\n",
    "\n",
    "                    data = query_graphql(start_time, end_time, route)\n",
    "                    print(f\"{datetime.now().strftime('%a %b %d %I:%M:%S %p')}: performed query.\")\n",
    "                          \n",
    "                    if data is None:  # API might refuse to cooperate\n",
    "                        print(\"API probably timed out\")\n",
    "                        continue\n",
    "                    elif len(data) == 0:  # some days somehow have no data\n",
    "                        print(f\"no data for {month}/{day}\")\n",
    "                        continue\n",
    "                    else:\n",
    "                        stops = produce_stops(data, route)\n",
    "                        print(f\"{datetime.now().strftime('%a %b %d %I:%M:%S %p')}: produced stops.\")\n",
    "                        #pprint.pprint(stops)\n",
    "                              \n",
    "                        buses = produce_buses(data)\n",
    "                        print(f\"{datetime.now().strftime('%a %b %d %I:%M:%S %p')}: produced buses.\")\n",
    "                        #pprint.pprint(buses)\n",
    "                        \n",
    "                        # select single stop that match stop_id\n",
    "                        stop = stops[stops['SID'] == stop_id].squeeze()\n",
    "                        # select buses that have matching DID with the stop. note* this will not select inbound\n",
    "                        buses = buses[buses['DID'] == stop['DID']]\n",
    "                        \n",
    "                        #pprint.pprint(buses)\n",
    "                        #pprint.pprint(stop)\n",
    "\n",
    "                        eclipses = find_eclipses(buses, stop)\n",
    "                        print(f\"{datetime.now().strftime('%a %b %d %I:%M:%S %p')}: found eclipses.\")\n",
    "                              \n",
    "                        nadirs = find_nadirs(eclipses)\n",
    "                        print(f\"{datetime.now().strftime('%a %b %d %I:%M:%S %p')}: found nadirs.\")\n",
    "                            \n",
    "                        nadirs[\"TIME\"] = nadirs[\"TIME\"].apply(lambda x: datetime.fromtimestamp(x//1000, timezone(timedelta(hours = -8))).strftime('%a %b %d %Y %I:%M%p'))\n",
    "                        nadirs[\"SID\"] = stop_id\n",
    "                        nadirs[\"DID\"] = stop[\"DID\"]\n",
    "                        nadirs[\"ROUTE\"] = route\n",
    "                        old_length = len(bus_stops)\n",
    "                        bus_stops = bus_stops.append(nadirs, sort = True)\n",
    "                        print(f\"{datetime.now().strftime('%a %b %d %I:%M:%S %p')}: finished processing.\")\n",
    "\n",
    "    # filter for directions\n",
    "    if len(directions) > 0:\n",
    "        bus_stops = bus_stops.loc[bus_stops['DID'].apply(lambda x: x in directions)]\n",
    "    \n",
    "    return bus_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 25 04:00:32 PM: starting processing on stop 5528 on route 14 on 2018-11-12.\n",
      "Fri Jan 25 04:00:44 PM: performed query.\n",
      "Fri Jan 25 04:00:45 PM: produced stops.\n",
      "Fri Jan 25 04:00:45 PM: produced buses.\n",
      "eclipses lmbda start\n",
      "eclipses lmbda end\n",
      "elapsed time for eclipses lmbda is: 1.4268510341644287 seconds\n",
      "Fri Jan 25 04:00:46 PM: found eclipses.\n",
      "Fri Jan 25 04:00:46 PM: found nadirs.\n",
      "Fri Jan 25 04:00:46 PM: finished processing.\n",
      "Fri Jan 25 04:00:46 PM: starting processing on stop 5528 on route 14 on 2018-11-13.\n",
      "Fri Jan 25 04:00:56 PM: performed query.\n",
      "Fri Jan 25 04:00:59 PM: produced stops.\n",
      "Fri Jan 25 04:00:59 PM: produced buses.\n",
      "eclipses lmbda start\n",
      "eclipses lmbda end\n",
      "elapsed time for eclipses lmbda is: 1.2461671829223633 seconds\n",
      "Fri Jan 25 04:01:01 PM: found eclipses.\n",
      "Fri Jan 25 04:01:01 PM: found nadirs.\n",
      "Fri Jan 25 04:01:01 PM: finished processing.\n",
      "Fri Jan 25 04:01:01 PM: starting processing on stop 5528 on route 14 on 2018-11-14.\n"
     ]
    }
   ],
   "source": [
    "new_stops = get_stops(dates, route, directions = ['14___O_F00'], new_stops = ['5528'], times = timespan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: parse direction as inbound/outbound? (remove route indicator)\n",
    "# filter by direction/stop if provided\n",
    "# split date/time\n",
    "new_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stops['DID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stops['SID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_waiting_time(df, start_time, end_time):\n",
    "    minute_range = [start_time.replace(minute = start_time.minute + i) for i in range(end_time.minute - start_time.minute)]\n",
    "    wait_times = pd.DataFrame(columns = [\"ROUTE\", \"TIME\", \"WAIT\"])\n",
    "    \n",
    "    for minute in minute_range:\n",
    "        print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stops[\"timestamp\"] = new_stops[\"TIME\"].apply(lambda x: datetime.strptime(x, '%a %b %d %Y %I:%M%p').timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stops['date'] = new_stops[\"TIME\"].apply(lambda x: datetime.strptime(x, '%a %b %d %Y %I:%M%p').date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = new_stops[['date', 'timestamp']].pivot_table(values = ['timestamp'], index = ['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot['timestamp'] = pivot['timestamp'].apply(lambda x: )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
